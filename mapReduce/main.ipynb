{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "import nltk\n",
    "import config\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating spark session\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------------------+--------+---------------+--------------------+\n",
      "| id|    number|          createdAt|    flag|       userName|                text|\n",
      "+---+----------+-------------------+--------+---------------+--------------------+\n",
      "|  0|1467810369|2009-04-06 22:19:45|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|  1|1467810672|2009-04-06 22:19:49|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|  2|1467810917|2009-04-06 22:19:53|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|  3|1467811184|2009-04-06 22:19:57|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|  4|1467811193|2009-04-06 22:19:57|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|  5|1467811372|2009-04-06 22:20:00|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|  6|1467811592|2009-04-06 22:20:03|NO_QUERY|        mybirch|         Need a hug |\n",
      "|  7|1467811594|2009-04-06 22:20:03|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|  8|1467811795|2009-04-06 22:20:05|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|  9|1467812025|2009-04-06 22:20:09|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "+---+----------+-------------------+--------+---------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# reading data from the source database\n",
    "df = spark.read.jdbc(\n",
    "    url        = f'jdbc:mysql://source-db:{config.MySQL.port}/{config.MySQL.database}',\n",
    "    table      = config.MySQL.table,\n",
    "    properties = {\n",
    "        'user'    : config.MySQL.user,\n",
    "        'password': config.MySQL.password,\n",
    "        'driver'  : 'com.mysql.cj.jdbc.Driver'\n",
    "    }\n",
    ")\n",
    "\n",
    "# df = df.limit(1_000_000)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- number: integer (nullable = true)\n",
      " |-- createdAt: timestamp (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- userName: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# observing schema of the data\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------------------+--------+--------------------+--------------------+\n",
      "|summary|               id|              number|    flag|            userName|                text|\n",
      "+-------+-----------------+--------------------+--------+--------------------+--------------------+\n",
      "|  count|          1599488|             1599488| 1599488|             1599488|             1599488|\n",
      "|   mean| 800030.493971821| 1.978032138980347E9|    NULL| 4.325887521835714E9|                NULL|\n",
      "| stddev|461875.0173308443|1.6960269568956092E8|    NULL|5.162733218454889E10|                NULL|\n",
      "|    min|                0|          1467810369|NO_QUERY|        000catnap000|                 ...|\n",
      "|    max|          1599999|          2147483647|NO_QUERY|          zzzzeus111|ï¿½ï¿½ï¿½ï¿½ï¿½ß§...|\n",
      "+-------+-----------------+--------------------+--------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# describing the dataset\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1599488"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing missing values\n",
    "df = df.dropna()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filtering out feature subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------+----------------------------------------------------------------------------------------------------+\n",
      "|          createdAt|       userName|                                                                                                text|\n",
      "+-------------------+---------------+----------------------------------------------------------------------------------------------------+\n",
      "|2009-04-06 22:19:45|_TheSpecialOne_|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Thir...|\n",
      "|2009-04-06 22:19:49|  scotthamilton|is upset that he can't update his Facebook by texting it... and might cry as a result  School tod...|\n",
      "|2009-04-06 22:19:53|       mattycus|           @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds|\n",
      "|2009-04-06 22:19:57|        ElleCTF|                                                     my whole body feels itchy and like its on fire |\n",
      "|2009-04-06 22:19:57|         Karoli|@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you al...|\n",
      "|2009-04-06 22:20:00|       joy_wolf|                                                                       @Kwesidei not the whole crew |\n",
      "|2009-04-06 22:20:03|        mybirch|                                                                                         Need a hug |\n",
      "|2009-04-06 22:20:03|           coZZ| @LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?|\n",
      "|2009-04-06 22:20:05|2Hood4Hollywood|                                                                @Tatiana_K nope they didn't have it |\n",
      "|2009-04-06 22:20:09|        mimismo|                                                                           @twittera que me muera ? |\n",
      "+-------------------+---------------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# selecting only the useful columns\n",
    "df = df.select(['createdAt', 'userName', 'text'])\n",
    "df.show(10, truncate= 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing usernames with placeholder 'user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------+----------------------------------------------------------------------------------------------------+\n",
      "|          createdAt|       userName|                                                                                                text|\n",
      "+-------------------+---------------+----------------------------------------------------------------------------------------------------+\n",
      "|2009-04-06 22:19:45|_TheSpecialOne_|            user http - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|\n",
      "|2009-04-06 22:19:49|  scotthamilton|is upset that he can't update his Facebook by texting it... and might cry as a result  School tod...|\n",
      "|2009-04-06 22:19:53|       mattycus|                user I dived many times for the ball. Managed to save 50%  The rest go out of bounds|\n",
      "|2009-04-06 22:19:57|        ElleCTF|                                                     my whole body feels itchy and like its on fire |\n",
      "|2009-04-06 22:19:57|         Karoli| user no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. |\n",
      "|2009-04-06 22:20:00|       joy_wolf|                                                                            user not the whole crew |\n",
      "|2009-04-06 22:20:03|        mybirch|                                                                                         Need a hug |\n",
      "|2009-04-06 22:20:03|           coZZ|      user hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?|\n",
      "|2009-04-06 22:20:05|2Hood4Hollywood|                                                                      user nope they didn't have it |\n",
      "|2009-04-06 22:20:09|        mimismo|                                                                                user que me muera ? |\n",
      "+-------------------+---------------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\n",
    "    # replacing every username with '@user'\n",
    "    colName= 'text',\n",
    "    col    = pyspark.sql.functions.regexp_replace(\n",
    "        pyspark.sql.functions.col('text'), \n",
    "        pattern    = r'@\\S*',\n",
    "        replacement= 'user'\n",
    "    )\n",
    ")\n",
    "df.show(10, truncate= 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing urls/links with the placeholder 'https'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------+----------------------------------------------------------------------------------------------------+\n",
      "|          createdAt|       userName|                                                                                                text|\n",
      "+-------------------+---------------+----------------------------------------------------------------------------------------------------+\n",
      "|2009-04-06 22:19:45|_TheSpecialOne_|            user http - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|\n",
      "|2009-04-06 22:19:49|  scotthamilton|is upset that he can't update his Facebook by texting it... and might cry as a result  School tod...|\n",
      "|2009-04-06 22:19:53|       mattycus|                user I dived many times for the ball. Managed to save 50%  The rest go out of bounds|\n",
      "|2009-04-06 22:19:57|        ElleCTF|                                                     my whole body feels itchy and like its on fire |\n",
      "|2009-04-06 22:19:57|         Karoli| user no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. |\n",
      "|2009-04-06 22:20:00|       joy_wolf|                                                                            user not the whole crew |\n",
      "|2009-04-06 22:20:03|        mybirch|                                                                                         Need a hug |\n",
      "|2009-04-06 22:20:03|           coZZ|      user hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?|\n",
      "|2009-04-06 22:20:05|2Hood4Hollywood|                                                                      user nope they didn't have it |\n",
      "|2009-04-06 22:20:09|        mimismo|                                                                                user que me muera ? |\n",
      "+-------------------+---------------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\n",
    "    # replacing http/https urls with 'http'\n",
    "    colName = 'text',\n",
    "    col     = pyspark.sql.functions.regexp_replace(\n",
    "        pyspark.sql.functions.col('text'), \n",
    "        pattern    = r'http\\S*',\n",
    "        replacement= 'http'\n",
    "    )\n",
    ")\n",
    "df.show(10, truncate= 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing the text using nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining pyspark tokenizer function\n",
    "@pyspark.sql.functions.udf(\n",
    "    returnType= pyspark.sql.types.ArrayType(\n",
    "        pyspark.sql.types.StringType()))\n",
    "def tokenize(text):\n",
    "    return nltk.tokenize.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------+----------------------------------------------------------------------------------------------------+\n",
      "|          createdAt|       userName|                                                                                                text|\n",
      "+-------------------+---------------+----------------------------------------------------------------------------------------------------+\n",
      "|2009-04-06 22:19:45|_TheSpecialOne_|[user, http, -, Awww, ,, that, 's, a, bummer, ., You, shoulda, got, David, Carr, of, Third, Day, ...|\n",
      "|2009-04-06 22:19:49|  scotthamilton|[is, upset, that, he, ca, n't, update, his, Facebook, by, texting, it, ..., and, might, cry, as, ...|\n",
      "|2009-04-06 22:19:53|       mattycus|[user, I, dived, many, times, for, the, ball, ., Managed, to, save, 50, %, The, rest, go, out, of...|\n",
      "|2009-04-06 22:19:57|        ElleCTF|                                           [my, whole, body, feels, itchy, and, like, its, on, fire]|\n",
      "|2009-04-06 22:19:57|         Karoli|[user, no, ,, it, 's, not, behaving, at, all, ., i, 'm, mad, ., why, am, i, here, ?, because, I, ...|\n",
      "|2009-04-06 22:20:00|       joy_wolf|                                                                       [user, not, the, whole, crew]|\n",
      "|2009-04-06 22:20:03|        mybirch|                                                                                      [Need, a, hug]|\n",
      "|2009-04-06 22:20:03|           coZZ|[user, hey, long, time, no, see, !, Yes, .., Rains, a, bit, ,, only, a, bit, LOL, ,, I, 'm, fine,...|\n",
      "|2009-04-06 22:20:05|2Hood4Hollywood|                                                              [user, nope, they, did, n't, have, it]|\n",
      "|2009-04-06 22:20:09|        mimismo|                                                                           [user, que, me, muera, ?]|\n",
      "+-------------------+---------------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\n",
    "    # tokenizing the text\n",
    "    colName= 'text',\n",
    "    col    = tokenize('text')\n",
    ")\n",
    "df.show(10, truncate= 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark stopword remover\n",
    "@pyspark.sql.functions.udf(\n",
    "    returnType= pyspark.sql.types.ArrayType(\n",
    "        pyspark.sql.types.StringType()))\n",
    "def removeStopWords(text):\n",
    "    return list(filter(\n",
    "        lambda w: w not in nltk.corpus.stopwords.words('english'), \n",
    "        text\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------+----------------------------------------------------------------------------------------------------+\n",
      "|          createdAt|       userName|                                                                                                text|\n",
      "+-------------------+---------------+----------------------------------------------------------------------------------------------------+\n",
      "|2009-04-06 22:19:45|_TheSpecialOne_|        [user, http, -, Awww, ,, 's, bummer, ., You, shoulda, got, David, Carr, Third, Day, ., ;, D]|\n",
      "|2009-04-06 22:19:49|  scotthamilton|[upset, ca, n't, update, Facebook, texting, ..., might, cry, result, School, today, also, ., Blah...|\n",
      "|2009-04-06 22:19:53|       mattycus|                 [user, I, dived, many, times, ball, ., Managed, save, 50, %, The, rest, go, bounds]|\n",
      "|2009-04-06 22:19:57|        ElleCTF|                                                             [whole, body, feels, itchy, like, fire]|\n",
      "|2009-04-06 22:19:57|         Karoli|                                       [user, ,, 's, behaving, ., 'm, mad, ., ?, I, ca, n't, see, .]|\n",
      "|2009-04-06 22:20:00|       joy_wolf|                                                                                 [user, whole, crew]|\n",
      "|2009-04-06 22:20:03|        mybirch|                                                                                         [Need, hug]|\n",
      "|2009-04-06 22:20:03|           coZZ| [user, hey, long, time, see, !, Yes, .., Rains, bit, ,, bit, LOL, ,, I, 'm, fine, thanks, ,, 's, ?]|\n",
      "|2009-04-06 22:20:05|2Hood4Hollywood|                                                                                   [user, nope, n't]|\n",
      "|2009-04-06 22:20:09|        mimismo|                                                                               [user, que, muera, ?]|\n",
      "+-------------------+---------------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\n",
    "    # removing stopwords\n",
    "    colName= 'text',\n",
    "    col    = removeStopWords('text')\n",
    ")\n",
    "df.show(10, truncate= 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the stemmer function\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "@pyspark.sql.functions.udf(\n",
    "    returnType= pyspark.sql.types.ArrayType(\n",
    "        pyspark.sql.types.StringType()))\n",
    "def stem(text):\n",
    "    return list(map(\n",
    "        stemmer.stem, \n",
    "        text\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------+-------------------------------------------------------------------------------------------------+\n",
      "|          createdAt|       userName|                                                                                             text|\n",
      "+-------------------+---------------+-------------------------------------------------------------------------------------------------+\n",
      "|2009-04-06 22:19:45|_TheSpecialOne_|     [user, http, -, awww, ,, 's, bummer, ., you, shoulda, got, david, carr, third, day, ., ;, d]|\n",
      "|2009-04-06 22:19:49|  scotthamilton|[upset, ca, n't, updat, facebook, text, ..., might, cri, result, school, today, also, ., blah, !]|\n",
      "|2009-04-06 22:19:53|       mattycus|                   [user, i, dive, mani, time, ball, ., manag, save, 50, %, the, rest, go, bound]|\n",
      "|2009-04-06 22:19:57|        ElleCTF|                                                           [whole, bodi, feel, itchi, like, fire]|\n",
      "|2009-04-06 22:19:57|         Karoli|                                       [user, ,, 's, behav, ., 'm, mad, ., ?, i, ca, n't, see, .]|\n",
      "|2009-04-06 22:20:00|       joy_wolf|                                                                              [user, whole, crew]|\n",
      "|2009-04-06 22:20:03|        mybirch|                                                                                      [need, hug]|\n",
      "|2009-04-06 22:20:03|           coZZ| [user, hey, long, time, see, !, ye, .., rain, bit, ,, bit, lol, ,, i, 'm, fine, thank, ,, 's, ?]|\n",
      "|2009-04-06 22:20:05|2Hood4Hollywood|                                                                                [user, nope, n't]|\n",
      "|2009-04-06 22:20:09|        mimismo|                                                                            [user, que, muera, ?]|\n",
      "+-------------------+---------------+-------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\n",
    "    # stemming words\n",
    "    colName= 'text',\n",
    "    col    = stem('text')\n",
    ")\n",
    "df.show(10, truncate= 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## joining the processed words back into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------+--------------------------------------------------------------------------------+\n",
      "|          createdAt|       userName|                                                                            text|\n",
      "+-------------------+---------------+--------------------------------------------------------------------------------+\n",
      "|2009-04-06 22:19:45|_TheSpecialOne_|       user http - awww , 's bummer . you shoulda got david carr third day . ; d|\n",
      "|2009-04-06 22:19:49|  scotthamilton|upset ca n't updat facebook text ... might cri result school today also . blah !|\n",
      "|2009-04-06 22:19:53|       mattycus|                  user i dive mani time ball . manag save 50 % the rest go bound|\n",
      "|2009-04-06 22:19:57|        ElleCTF|                                                 whole bodi feel itchi like fire|\n",
      "|2009-04-06 22:19:57|         Karoli|                                     user , 's behav . 'm mad . ? i ca n't see .|\n",
      "|2009-04-06 22:20:00|       joy_wolf|                                                                 user whole crew|\n",
      "|2009-04-06 22:20:03|        mybirch|                                                                        need hug|\n",
      "|2009-04-06 22:20:03|           coZZ|      user hey long time see ! ye .. rain bit , bit lol , i 'm fine thank , 's ?|\n",
      "|2009-04-06 22:20:05|2Hood4Hollywood|                                                                   user nope n't|\n",
      "|2009-04-06 22:20:09|        mimismo|                                                                user que muera ?|\n",
      "+-------------------+---------------+--------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\n",
    "    colName= 'text',\n",
    "    col    = pyspark.sql.functions.concat_ws(' ', 'text')\n",
    ")\n",
    "df.show(10, truncate= 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing data to mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "( df.write\n",
    "    .format('mongodb')\n",
    "    .option('database'      , f'{config.MongoDb.database}')\n",
    "    .option('collection'    , f'{config.MongoDb.collection}')\n",
    "    .option('connection.uri', f'mongodb://{config.MongoDb.user}:{config.MongoDb.password}@{config.MongoDb.host}:{config.MongoDb.port}')\n",
    "    .mode('overwrite')\n",
    "\t.save()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
